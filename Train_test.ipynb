{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\MachineLearning-Conda\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import math\n",
    "import h5py\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset with one-hot encoded Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw=h5py.File('dataset_1.h5','r')\n",
    "batch1=X_raw.get('images') # tf supports float32 only\n",
    "Y_raw=h5py.File('OneHotGT_1.h5','r')\n",
    "label1=Y_raw.get('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11160, 2500)\n",
      "(11160, 124)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "#Debug\n",
    "print(batch1.shape)\n",
    "print(label1.shape)\n",
    "print(batch1.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw=h5py.File('TestImage.h5','r')\n",
    "testbatch=X_raw.get('images')\n",
    "Y_raw=h5py.File('TestLabel.h5','r')\n",
    "testlabel=Y_raw.get('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9920, 2500)\n",
      "(9920, 124)\n"
     ]
    }
   ],
   "source": [
    "#Debug\n",
    "print(testbatch.shape)\n",
    "print(testlabel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know that tamil character images are 50 pixels in each dimension.\n",
    "img_size = 50\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = img_size * img_size\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "num_channels = 1\n",
    "\n",
    "# Number of classes, one class for each of 124 characters\n",
    "num_classes = 124"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples) (m, Hi, Wi, Ci)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) (m, n_y)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    num_features=X.shape[1]\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "     \n",
    "        # Data ALready Shuffled \n",
    "   \n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch_Y = Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = X[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch_Y = Y[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(np.argmax(cls_true[i]))\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x249c60afa58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mini_batch1=random_mini_batches(batch1,label1,9)\n",
    "x_batch=mini_batch1[1000][0]\n",
    "y_label=mini_batch1[1000][1]\n",
    "plot_images(x_batch,y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### layer dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convolutional Layer 1.\n",
    "filter_size1 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters2 = 36         # There are 36 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 124            # Number of neurons in fully-connected layer.import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Graph Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create New weigtht and biases\n",
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create ConV Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_conv_layer(input,              # The previous layer.\n",
    "                   num_input_channels, # Num. channels in prev. layer.\n",
    "                   filter_size,        # Width and height of each filter.\n",
    "                   num_filters,        # Number of filters.\n",
    "                   use_pooling=True):  # Use 2x2 max-pooling.\n",
    "\n",
    "    # Shape of the filter-weights for the convolution.\n",
    "    \n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "    # Create new weights aka. filters with the given shape.\n",
    "    weights = new_weights(shape=shape)\n",
    "\n",
    "    # Create new biases, one for each filter.\n",
    "    biases = new_biases(length=num_filters)\n",
    "\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=[1, 1, 1, 1],\n",
    "                         padding='SAME')\n",
    "\n",
    "    # Add the biases to the results of the convolution.\n",
    "    # A bias-value is added to each filter-channel.\n",
    "    layer += biases\n",
    "\n",
    "    # Use pooling to down-sample the image resolution?\n",
    "    if use_pooling:\n",
    "        \n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME')\n",
    "\n",
    "    \n",
    "    layer = tf.nn.relu(layer)    \n",
    "    return layer, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_layer(layer):\n",
    "    # Get the shape of the input layer.\n",
    "    layer_shape = layer.get_shape()\n",
    "    \n",
    "    num_features = layer_shape[1:4].num_elements()    \n",
    "    \n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    \n",
    "    return layer_flat, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_fc_layer(input,          # The previous layer.\n",
    "                 num_inputs,     # Num. inputs from prev. layer.\n",
    "                 num_outputs,    # Num. outputs.\n",
    "                 use_relu=True): # Use Rectified Linear Unit (ReLU)?\n",
    "\n",
    "    # Create new weights and biases.\n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_biases(length=num_outputs)\n",
    "\n",
    "    # Calculate the layer as the matrix multiplication of\n",
    "    # the input and weights, and then add the bias-values.\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "\n",
    "    # Use ReLU?\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify shape of original image dataset\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#debug\n",
    "x_image.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true') # one-hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_cls = tf.argmax(y_true, axis=1) # single number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv1, weights_conv1 = \\\n",
    "    new_conv_layer(input=x_image,\n",
    "                   num_input_channels=num_channels,\n",
    "                   filter_size=filter_size1,\n",
    "                   num_filters=num_filters1,\n",
    "                   use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_3:0' shape=(?, 25, 25, 16) dtype=float32>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#debug\n",
    "layer_conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv2, weights_conv2 = \\\n",
    "    new_conv_layer(input=layer_conv1,\n",
    "                   num_input_channels=num_filters1,\n",
    "                   filter_size=filter_size2,\n",
    "                   num_filters=num_filters2,\n",
    "                   use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_4:0' shape=(?, 13, 13, 36) dtype=float32>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#debug\n",
    "layer_conv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_flat, num_features = flatten_layer(layer_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_6:0' shape=(?, 6084) dtype=float32>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#debug\n",
    "layer_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_5:0' shape=(?, 124) dtype=float32>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#debug\n",
    "layer_fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(layer_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost-function to be optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc1,\n",
    "                                                        labels=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter for total number of iterations performed so far.\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    # Ensure we update the global variable rather than a local copy.\n",
    "    global total_iterations\n",
    "\n",
    "    # Start-time used for printing time-usage below.\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(total_iterations,\n",
    "                   total_iterations + num_iterations):\n",
    "\n",
    "        # Get a batch of training examples.\n",
    "        # x_batch now holds a batch of images and\n",
    "        # y_true_batch are the true labels for those images.\n",
    "        x_batch, y_true_batch = mini_batch1[i][0],mini_batch1[i][1]\n",
    "\n",
    "        # Put the batch into a dict with the proper names\n",
    "        # for placeholder variables in the TensorFlow graph.\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "\n",
    "        # Run the optimizer using this batch of training data.\n",
    "        # TensorFlow assigns the variables in feed_dict_train\n",
    "        # to the placeholder variables and then runs the optimizer.\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "        # Print status every 100 iterations.\n",
    "        if i % 100 == 0:\n",
    "            # Calculate the accuracy on the training-set.\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "\n",
    "            # Message for printing.\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "\n",
    "            # Print it.\n",
    "            print(msg.format(i + 1, acc))\n",
    "\n",
    "    # Update the total number of iterations performed.\n",
    "    total_iterations += num_iterations\n",
    "\n",
    "    # Ending time.\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example_errors(cls_pred, correct):\n",
    "    # This function is called from print_test_accuracy() below.\n",
    "\n",
    "    # cls_pred is an array of the predicted class-number for\n",
    "    # all images in the test-set.\n",
    "\n",
    "    # correct is a boolean array whether the predicted class\n",
    "    # is equal to the true class for each image in the test-set.\n",
    "\n",
    "    # Negate the boolean array.\n",
    "    incorrect = (correct == False)\n",
    "    \n",
    "    # Get the images from the test-set that have been\n",
    "    # incorrectly classified.\n",
    "    images = Y_test[incorrect]\n",
    "    \n",
    "    # Get the predicted classes for those images.\n",
    "    cls_pred = cls_pred[incorrect]\n",
    "\n",
    "    # Get the true classes for those images.\n",
    "    cls_true = data.test.cls[incorrect]\n",
    "    \n",
    "    # Plot the first 9 images.\n",
    "    plot_images(images=images[0:9],\n",
    "                cls_true=cls_true[0:9],\n",
    "                cls_pred=cls_pred[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cls_pred):\n",
    "    # This is called from print_test_accuracy() below.\n",
    "\n",
    "    # cls_pred is an array of the predicted class-number for\n",
    "    # all images in the test-set.\n",
    "\n",
    "    # Get the true classifications for the test-set.\n",
    "    cls_true = np.argmax(testlabels)\n",
    "    \n",
    "    # Get the confusion matrix using sklearn.\n",
    "    cm = confusion_matrix(y_true=cls_true,\n",
    "                          y_pred=cls_pred)\n",
    "\n",
    "    # Print the confusion matrix as text.\n",
    "    print(cm)\n",
    "\n",
    "    # Plot the confusion matrix as an image.\n",
    "    plt.matshow(cm)\n",
    "\n",
    "    # Make various adjustments to the plot.\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, range(num_classes))\n",
    "    plt.yticks(tick_marks, range(num_classes))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "\n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test-set into smaller batches of this size.\n",
    "test_batch_size = 256\n",
    "\n",
    "def print_test_accuracy(show_example_errors=False,\n",
    "                        show_confusion_matrix=False):\n",
    "\n",
    "    # Number of images in the test-set.\n",
    "    num_test = len(testbatch)\n",
    "\n",
    "    # Allocate an array for the predicted classes which\n",
    "    # will be calculated in batches and filled into this array.\n",
    "    cls_pred = np.zeros(shape=num_test, dtype=np.int)\n",
    "\n",
    "    # Now calculate the predicted classes for the batches.\n",
    "    # We will just iterate through all the batches.\n",
    "    # There might be a more clever and Pythonic way of doing this.\n",
    "\n",
    "    # The starting index for the next batch is denoted i.\n",
    "    i = 0\n",
    "\n",
    "    while i < num_test:\n",
    "        # The ending index for the next batch is denoted j.\n",
    "        j = min(i + test_batch_size, num_test)\n",
    "\n",
    "        # Get the images from the test-set between index i and j.\n",
    "        images = testbatch[i:j,:]\n",
    "\n",
    "        # Get the associated labels.\n",
    "        labels = testlabel[i:j, :] # one hot encoded\n",
    "\n",
    "        # Create a feed-dict with these images and labels.\n",
    "        feed_dict = {x: images,\n",
    "                     y_true: labels}\n",
    "\n",
    "        # Calculate the predicted class using TensorFlow.\n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "\n",
    "        # Set the start-index for the next batch to the\n",
    "        # end-index of the current batch.\n",
    "        i = j\n",
    "\n",
    "    # Convenience variable for the true class-numbers of the test-set.\n",
    "    cls_true = np.argmax(testlabel)\n",
    "    cls_pred = np.argmax(cls_pred)\n",
    "    print(cls_true.shape)\n",
    "    print(cls_pred.shape)\n",
    "    # Create a boolean array whether each image is correctly classified.\n",
    "    correct = (cls_true[:] == cls_pred[:])\n",
    "    print(cls_true,cls_pred,correct)\n",
    "\n",
    "    # Calculate the number of correctly classified images.\n",
    "    # When summing a boolean array, False means 0 and True means 1.\n",
    "    correct_sum = np.sum(correct)\n",
    "\n",
    "    # Classification accuracy is the number of correctly classified\n",
    "    # images divided by the total number of images in the test-set.\n",
    "    acc = float(correct_sum) / num_test\n",
    "\n",
    "    # Print the accuracy.\n",
    "    msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, correct_sum, num_test))\n",
    "\n",
    "    # Plot some examples of mis-classifications, if desired.\n",
    "    if show_example_errors:\n",
    "        print(\"Example errors:\")\n",
    "        plot_example_errors(cls_pred=cls_pred, correct=correct)\n",
    "\n",
    "    # Plot the confusion matrix, if desired.\n",
    "    if show_confusion_matrix:\n",
    "        print(\"Confusion Matrix:\")\n",
    "        plot_confusion_matrix(cls_pred=cls_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
